#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import re
import numpy as np
import torch
from pathlib import Path
from argparse import ArgumentParser
from datetime import datetime

from utils.easy_renderer_alpha import EasyRenderer   # ä¸æ”¹ easy_renderer
import torchvision

# å˜—è©¦åŒ¯å…¥ imageio åš mp4
try:
    import imageio.v2 as imageio
    HAS_IMAGEIO = True
except ImportError:
    HAS_IMAGEIO = False
    print("[Warn] imageio æœªå®‰è£ï¼Œå°‡åªè¼¸å‡º PNGï¼Œä¸ç”¢ç”Ÿ mp4ï¼ˆå¯ä½¿ç”¨ pip install imageio[ffmpeg]ï¼‰")

# ----------------------------
# COLMAP helpers
# ----------------------------
def read_cameras_txt(path: Path):
    cams = {}
    with open(path, "r") as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith("#"):
                continue
            toks = line.split()
            cam_id = int(toks[0])
            model  = toks[1].upper()
            width  = int(toks[2])
            height = int(toks[3])
            params = np.array(list(map(float, toks[4:])), dtype=np.float64)
            cams[cam_id] = {
                "model": model,
                "width": width,
                "height": height,
                "params": params
            }
    return cams


def read_images_txt(path: Path):
    imgs = {}
    with open(path, "r") as f:
        lines = [l.strip() for l in f]
    i = 0
    while i < len(lines):
        line = lines[i]
        if not line or line.startswith("#"):
            i += 1
            continue
        toks = line.split()
        # IMAGE_ID qw qx qy qz tx ty tz CAMERA_ID NAME
        q = np.array(list(map(float, toks[1:5])), dtype=np.float64)   # qw qx qy qz
        t = np.array(list(map(float, toks[5:8])), dtype=np.float64)   # tx ty tz
        cam_id = int(toks[8])
        name   = " ".join(toks[9:])
        imgs[name] = {"qvec": q, "tvec": t, "cam_id": cam_id}
        i += 2  # skip 2D points line
    return imgs


def qvec2rotmat(q):
    qw, qx, qy, qz = q
    return np.array([
        [1 - 2*(qy*qy + qz*qz),     2*(qx*qy - qz*qw),     2*(qx*qz + qy*qw)],
        [    2*(qx*qy + qz*qw), 1 - 2*(qx*qx + qz*qz),     2*(qy*qz - qx*qw)],
        [    2*(qx*qz - qy*qw),     2*(qy*qz + qx*qw), 1 - 2*(qx*qx + qy*qy)]
    ], dtype=np.float64)


def intrinsics_from_entry(entry):
    model = entry["model"]
    w, h = entry["width"], entry["height"]
    p = entry["params"]

    if model in ("PINHOLE", "OPENCV", "OPENCV_FISHEYE", "BROWN_CONRADY", "FULL_OPENCV"):
        fx, fy, cx, cy = p[0], p[1], p[2], p[3]
    elif model in ("SIMPLE_PINHOLE", "SIMPLE_RADIAL", "RADIAL"):
        fx = fy = p[0]
        cx = p[1]
        cy = p[2]
    else:
        raise NotImplementedError(f"Unsupported camera model: {model}")

    K = np.array([[fx, 0,  cx],
                  [0,  fy, cy],
                  [0,  0,   1]], dtype=np.float32)
    return K.astype(np.float32), int(h), int(w)

# ----------------------------
# Pose loader
# ----------------------------
def load_poses(
    source_path: str,
    images_subdir: str = "test",
    cameras_subdir: str = "test",
    cameras_filename: str = "cameras.txt",
):
    """
    å¾ source_path/sparse/<images_subdir>/images.txt
    å’Œ source_path/sparse/<cameras_subdir>/<cameras_filename>
    è®€å– COLMAP pose + intrinsicsã€‚
    """
    src = Path(source_path)
    imgs_txt = src / "sparse" / images_subdir / "images.txt"
    cams_txt = src / "sparse" / cameras_subdir / cameras_filename

    if not imgs_txt.exists():
        raise FileNotFoundError(f"Missing images.txt: {imgs_txt}")
    if not cams_txt.exists():
        raise FileNotFoundError(f"Missing cameras file: {cams_txt}")

    cams = read_cameras_txt(cams_txt)
    imgs = read_images_txt(imgs_txt)
    cam_ids_sorted = sorted(cams.keys())

    items = []
    for name, meta in imgs.items():
        cam_id = meta["cam_id"]
        if cam_id in cams:
            entry = cams[cam_id]
        else:
            # ä¿éšªè™•ç†ï¼šå¦‚æœ images è£¡çš„ CAMERA_ID è·Ÿ cameras.txt ä¸ match
            if len(cam_ids_sorted) == 1:
                entry = cams[cam_ids_sorted[0]]
            elif 0 <= cam_id < len(cam_ids_sorted):
                entry = cams[cam_ids_sorted[cam_id]]
            else:
                raise KeyError(f"CAMERA_ID {cam_id} not in {cam_ids_sorted}")

        K, H, W = intrinsics_from_entry(entry)

        R = qvec2rotmat(meta["qvec"])  # world->camera
        t = meta["tvec"].reshape(3, 1)
        w2c = np.eye(4, dtype=np.float32)
        w2c[:3, :3] = R.astype(np.float32)
        w2c[:3, 3]  = t[:, 0].astype(np.float32)

        items.append((w2c, K, H, W, name))
    return items

# ----------------------------
# Find largb model directory
# ----------------------------
_TIMESTAMP_RE = re.compile(r"^\d{8}-\d{6}$")  # e.g., 20251022-205233

def _parse_ts(name: str):
    try:
        return datetime.strptime(name, "%Y%m%d-%H%M%S")
    except Exception:
        return None


def find_latest_model_dir(renderer_base: Path, scene_seq: str) -> Path:
    root = renderer_base / scene_seq
    if not root.exists():
        raise FileNotFoundError(f"Renderer scene root not found: {root}")

    subdirs = [p for p in root.iterdir() if p.is_dir()]
    if not subdirs:
        raise FileNotFoundError(f"No subdirectories under: {root}")

    ts_dirs = [(p, _parse_ts(p.name)) for p in subdirs if _TIMESTAMP_RE.match(p.name)]
    ts_dirs = [(p, ts) for p, ts in ts_dirs if ts is not None]
    if ts_dirs:
        ts_dirs.sort(key=lambda x: x[1], reverse=True)
        return ts_dirs[0][0]

    subdirs.sort(key=lambda p: p.stat().st_mtime, reverse=True)
    return subdirs[0]

# ===== axis-angle æ—‹è½‰ï¼ˆåœ¨ä¸–ç•Œåº§æ¨™ç¹æŸå€‹ axis è½‰ï¼‰ =====
def axis_angle_rotation(axis: np.ndarray, theta: float) -> np.ndarray:
    axis = axis.astype(np.float64)
    axis = axis / (np.linalg.norm(axis) + 1e-8)
    x, y, z = axis
    c = np.cos(theta)
    s = np.sin(theta)
    t = 1.0 - c
    R = np.array([
        [t*x*x + c,     t*x*y - s*z, t*x*z + s*y],
        [t*x*y + s*z,   t*y*y + c,   t*y*z - s*x],
        [t*x*z - s*y,   t*y*z + s*x, t*z*z + c  ],
    ], dtype=np.float64)
    return R

# ----------------------------
# Main
# ----------------------------
def main():
    ap = ArgumentParser()
    ap.add_argument("--source_path", required=True,
                    help="è³‡æ–™æ ¹ç›®éŒ„ï¼ˆåº•ä¸‹æœ‰ sparse/ï¼Œé è¨­è®€ sparse/testï¼‰")

    # é è¨­è®€ test
    ap.add_argument("--images_subdir", default="test",
                    help="è®€ images.txt çš„å­è³‡æ–™å¤¾ï¼ˆé è¨­ sparse/testï¼‰")
    ap.add_argument("--cameras_subdir", default="test",
                    help="è®€ cameras çš„å­è³‡æ–™å¤¾ï¼ˆé è¨­ sparse/testï¼‰")
    ap.add_argument("--cameras_filename", default="cameras.txt",
                    help="cameras æª”åï¼ˆé è¨­ cameras.txtï¼‰")
    
    # æ¨¡å‹ä¾†æºï¼ˆGraphDECO / EasyRenderer æ¨¡å‹ï¼‰
    ap.add_argument("--model_path", default=None,
                    help="ç›´æ¥æŒ‡å®š EasyRenderer æ¨¡å‹è³‡æ–™å¤¾ï¼ˆè¦†è“‹è‡ªå‹•æœå°‹ï¼‰")
    ap.add_argument("--renderer_base", default=None,
                    help="æ¨¡å‹æ ¹ç›®éŒ„ï¼ˆåº•ä¸‹æœ‰ <scene_seq>/<timestamp>ï¼‰")

    # scene_seq
    ap.add_argument("--scene_seq", default=None,
                    help="scene/seq åç¨±ï¼ŒæœªæŒ‡å®šå‰‡å– source_path çš„æœ€å¾Œä¸€å±¤ç›®éŒ„å")

    ap.add_argument("--iteration", type=int, default=10000,
                    help="EasyRenderer è¦è¼‰å…¥çš„ iterationï¼ˆå°æ‡‰ä½ è¨“ç·´å¥½çš„ ckptï¼‰")

    # RGB è¼¸å‡ºè³‡æ–™å¤¾
    ap.add_argument("--out_dir", default=None,
                    help="render RGB è¼¸å‡ºè³‡æ–™å¤¾ï¼ˆæœªæŒ‡å®šå‰‡ä¸Ÿåˆ° model_path/test_packï¼‰")

    # mp4 fps
    ap.add_argument("--fps", type=int, default=30,
                    help="è¼¸å‡º mp4 çš„ FPSï¼ˆé è¨­ 30ï¼‰")

    # ç¸½ frame æ•¸é‡ï¼ˆåŒ…å«é ­å°¾ï¼‰
    ap.add_argument("--num_frames", type=int, default=150,
                    help="æ•´æ®µå½±ç‰‡è¦è¼¸å‡ºçš„ç¸½ frame æ•¸ï¼ˆé è¨­ 150ï¼‰")

    args = ap.parse_args()
    
    # è§£æ scene_seq
    src = Path(args.source_path).resolve()
    if args.scene_seq is not None:
        scene_seq = args.scene_seq
    else:
        if len(src.parts) >= 1:
            scene_seq = src.parts[-1]
        else:
            raise RuntimeError("ç„¡æ³•è‡ªå‹•æ¨å° scene_seqï¼Œè«‹ç”¨ --scene_seq æŒ‡å®š")

    # è§£æ model_path
    if args.model_path is not None:
        model_path = Path(args.model_path).resolve()
        if not model_path.exists():
            raise FileNotFoundError(f"--model_path ä¸å­˜åœ¨: {model_path}")
    else:
        if args.renderer_base is None:
            raise ValueError("è«‹æä¾› --renderer_base æˆ–ç›´æ¥æŒ‡å®š --model_path")
        renderer_base = Path(args.renderer_base).resolve()
        model_path = find_latest_model_dir(renderer_base, scene_seq)
    print(f"[EasyRenderer RGB] model_path={model_path}  iteration={args.iteration}")

    # åˆå§‹åŒ– renderer
    er = EasyRenderer(model_path=str(model_path), iteration=args.iteration)

    # è¼‰å…¥ posesï¼ˆimages.txt + cameras.txtï¼‰ï¼Œé è¨­ sparse/test
    items = load_poses(
        source_path=str(src),
        images_subdir=args.images_subdir,
        cameras_subdir=args.cameras_subdir,
        cameras_filename=args.cameras_filename,
    )
    print(f"Loaded {len(items)} poses from {src}/sparse/{args.images_subdir}/images.txt")

    if len(items) < 1:
        raise RuntimeError("è‡³å°‘éœ€è¦ä¸€å€‹ test view")

    # ä¾ç…§æª”åæ’åºï¼Œå–ã€Œä¸­é–“é‚£ä¸€å¼µã€çš„æ–¹å‘ç•¶ base
    items_sorted = sorted(items, key=lambda x: x[-1])
    mid_idx = len(items_sorted) // 2
    w2c_base, K_base, H_base, W_base, name_base = items_sorted[mid_idx]
    print(f"Base view for 360Â° spin (orientation): {name_base}")

    # intrinsics / resolution ç”¨ base viewï¼Œä¸¦æŠŠ FOV æ‹‰å»£ (fx, fy x 0.8)
    K = K_base.copy().astype(np.float32)
    K[0, 0] *= 0.8  # fx
    K[1, 1] *= 0.8  # fy
    H, W = H_base, W_base
    print("Scaled intrinsics: fx, fy = ",
          float(K[0, 0]), float(K[1, 1]))

    # ---------- æ‰€æœ‰ camera center + bbox ä¸­å¿ƒ ----------
    centers = []
    up_vecs = []   # æ¯å€‹ç›¸æ©Ÿçš„ã€Œup å‘é‡ã€ï¼ˆä¸–ç•Œåº§æ¨™ï¼‰
    for (w2c, _, _, _, _) in items:
        R_i = w2c[:3, :3].astype(np.float64)   # world -> camera
        t_i = w2c[:3, 3].astype(np.float64)
        C_i = -R_i.T @ t_i                     # camera center in world

        R_c2w_i = R_i.T                        # camera -> world
        # COLMAP çš„ camera y è»¸æ˜¯ã€Œå¾€ä¸‹ã€ï¼Œæ‰€ä»¥å– -y ç•¶ã€Œupã€
        up_i = -R_c2w_i[:, 1]

        centers.append(C_i)
        up_vecs.append(up_i)

    centers = np.stack(centers, axis=0)
    up_vecs = np.stack(up_vecs, axis=0)

    # bbox å¹¾ä½•ä¸­å¿ƒ
    min_xyz = centers.min(axis=0)
    max_xyz = centers.max(axis=0)
    C_bbox = 0.5 * (min_xyz + max_xyz)

    # yï¼ˆé«˜åº¦ï¼‰ç”¨å¹³å‡ï¼Œé¿å…å¤ªé«˜/å¤ªä½ outlier
    C = C_bbox.copy()
    C[1] = centers[:, 1].mean()

    print("BBox center (world):", C_bbox)
    print("Final spin center (world):", C)

    # ---------- å…¨åŸŸ up å‘é‡ï¼ˆä¼°è¨ˆä¸–ç•Œçš„ã€Œæ­£ä¸Šæ–¹ã€ï¼‰ ----------
    global_up = up_vecs.mean(axis=0)
    global_up = global_up / (np.linalg.norm(global_up) + 1e-8)
    print("Estimated global up (world):", global_up)

    # base çš„ camera-to-world æ—‹è½‰
    R_wc_base = w2c_base[:3, :3].astype(np.float64)  # world -> camera
    R_c2w_base = R_wc_base.T                         # camera -> world

    # base çš„ã€Œå‰æ–¹ã€æ–¹å‘ï¼ˆcamera z è»¸åœ¨ world ä¸­ï¼‰
    forward0 = R_c2w_base[:, 2]

    # æŠŠ forward0 æŠ•å½±åˆ° global_up çš„æ°´å¹³é¢ï¼Œå»æ‰ pitchï¼Œä½¿å…¶ã€Œæ°´å¹³ã€
    forward0_proj = forward0 - np.dot(forward0, global_up) * global_up
    forward0_proj_norm = forward0_proj / (np.linalg.norm(forward0_proj) + 1e-8)

    # é€é global_up èˆ‡ forward0_proj_norm å»ºç«‹ã€Œæ‰¶æ­£å¾Œã€çš„ base æ—‹è½‰
    right0 = np.cross(global_up, forward0_proj_norm)
    right0 = right0 / (np.linalg.norm(right0) + 1e-8)
    up0 = np.cross(forward0_proj_norm, right0)

    R_c2w_base_level = np.stack([right0, up0, forward0_proj_norm], axis=1)

    # num_frames
    num_frames = max(2, int(args.num_frames))
    print(f"Generating {num_frames} frames for 360Â° horizontal rotation around scene center...")

    if args.out_dir is None:
        out_dir = model_path / "test_pack"
    else:
        out_dir = Path(args.out_dir).resolve()
    png_dir = out_dir / "png"
    png_dir.mkdir(parents=True, exist_ok=True)
    out_dir.mkdir(parents=True, exist_ok=True)

    # æ ¹æ“š out_dir è·¯å¾‘æ±ºå®šå½±ç‰‡åç¨±
    video_name = "video.mp4"
    parts = set(out_dir.parts)
    if "baseline" in parts:
        video_name = "3dgs.mp4"
    elif "ours" in parts:
        video_name = "ours.mp4"

    print(f"PNG will be saved to : {png_dir}")
    print(f"MP4 will be saved to : {out_dir / video_name}")


    frames_for_video = []

    # é€ frame ç¹ global_up åš 360Â° æ°´å¹³æ—‹è½‰
    for idx in range(num_frames):
        theta = 2.0 * np.pi * idx / num_frames   # 0 ~ 2Ï€

        # åœ¨ã€Œä¸–ç•Œåº§æ¨™ã€ç¹ global_up æ—‹è½‰
        R_yaw_world = axis_angle_rotation(global_up, theta)
        R_c2w_new = R_yaw_world @ R_c2w_base_level

        # world -> camera
        R_new = R_c2w_new.T.astype(np.float32)
        # t_new è®“ camera center å›ºå®šåœ¨ C
        t_new = (-R_new @ C.astype(np.float32))

        # çµ„æˆæ–°çš„ w2c
        w2c_new = np.eye(4, dtype=np.float32)
        w2c_new[:3, :3] = R_new
        w2c_new[:3, 3]  = t_new

        # æ¸²æŸ“
        rgb, alpha_map, depth = er.render(w2c_new, K, H, W)
        rgb = rgb.clamp(0, 1).float()

        # ğŸ” æŠŠç•«é¢ä¸Šä¸‹ç¿»è½‰ï¼ˆä¿®æ­£ upside-downï¼‰
        rgb = torch.flip(rgb, dims=[1])  # [3, H, W]ï¼Œç¶­åº¦ 1 æ˜¯å‚ç›´æ–¹å‘

        # å­˜ PNG
        frame_name = f"frame_{idx:04d}.png"
        frame_path = png_dir / frame_name
        torchvision.utils.save_image(rgb.cpu(), str(frame_path))

        # æ”¶é›†çµ¦ mp4
        if HAS_IMAGEIO:
            frame = (rgb.cpu().numpy().transpose(1, 2, 0) * 255.0)
            frame = np.clip(frame, 0, 255).astype(np.uint8)
            frames_for_video.append(frame)

        if idx % 20 == 0 or idx == num_frames - 1:
            print(f"Rendered frame {idx+1}/{num_frames} -> {frame_path.name}")

    # è¼¸å‡º mp4
    if HAS_IMAGEIO and len(frames_for_video) > 0:
        video_path = out_dir / video_name
        imageio.mimsave(video_path, frames_for_video, fps=args.fps)
        print(f"[Video] Saved mp4 to: {video_path}")

    elif not HAS_IMAGEIO:
        print("[Video] è·³é mp4 è¼¸å‡ºï¼Œå› ç‚ºæ²’æœ‰å®‰è£ imageioï¼ˆpip install imageio[ffmpeg]ï¼‰")
    else:
        print("[Video] æ²’æœ‰ä»»ä½• frameï¼Œè¢«è·³éã€‚")

    print(f"Done! Saved {num_frames} PNG images to: {png_dir}")

if __name__ == "__main__":
    main()
